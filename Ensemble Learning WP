import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import VotingRegressor
from keras.models import Sequential
from keras.layers import Conv1D, Flatten, Dense
import matplotlib.pyplot as plt

# Loading and prepare the data
wind_speed = [1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5, 10, 10.5, 11, 11.5, 12, 12.5, 13, 13.5, 14, 14.5, 15, 15.5, 16, 16.5, 17, 17.5, 18]
power_output = [109, 169, 207, 231, 215, 242, 292, 367, 309, 362, 363, 329, 330, 346, 665.7, 779.8, 942.5, 1073.30, 1200.20, 1329.50, 1354.00, 1385.00, 1366.00, 1364.80, 1501.30, 1515.50, 1498.40, 1521.30, 1522.10, 1526.30, 1530.20, 1524.20, 1531.50, 1525.50]

df = pd.DataFrame({'Wind_Speed': wind_speed, 'Power_Output': power_output[:len(wind_speed)]})
X = df[['Wind_Speed']]
y = df['Power_Output']

# Normalizing the data
scaler_X = MinMaxScaler(feature_range=(0, 1))
scaler_y = MinMaxScaler(feature_range=(0, 1))
X_scaled = scaler_X.fit_transform(X)
y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))

# Reshaping the data for CNN
X_scaled_cnn = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)
X_train_cnn, X_test_cnn = train_test_split(X_scaled_cnn, test_size=0.2, random_state=42)

# Defining individual models
model_lr = LinearRegression()
model_dt = DecisionTreeRegressor()

# Defining and train the CNN model
cnn_model = Sequential()
cnn_model.add(Conv1D(filters=64, kernel_size=1, activation='relu', input_shape=(X_train_cnn.shape[1], 1)))
cnn_model.add(Flatten())
cnn_model.add(Dense(32, activation='relu'))
cnn_model.add(Dense(1))
cnn_model.compile(loss='mean_squared_error', optimizer='adam')
cnn_model.fit(X_train_cnn, y_train, epochs=100, batch_size=32, verbose=2)

# Training individual models
model_lr.fit(X_train, y_train)
model_dt.fit(X_train, y_train)

# Making predictions with individual models
y_pred_lr = model_lr.predict(X_test)
y_pred_dt = model_dt.predict(X_test)
y_pred_cnn = cnn_model.predict(X_test_cnn)

# Reshaping predictions to 2D for inverse_transform
y_pred_lr = y_pred_lr.reshape(-1, 1)
y_pred_dt = y_pred_dt.reshape(-1, 1)
y_pred_cnn = y_pred_cnn.reshape(-1, 1)
y_test = y_test.reshape(-1, 1)

# Inverse transforming the predictions
y_pred_lr = scaler_y.inverse_transform(y_pred_lr)
y_pred_dt = scaler_y.inverse_transform(y_pred_dt)
y_pred_cnn = scaler_y.inverse_transform(y_pred_cnn)
y_test = scaler_y.inverse_transform(y_test)

# Creating and train an ensemble model
ensemble_model = VotingRegressor(estimators=[
    ('lr', model_lr),
    ('dt', model_dt)
])
ensemble_model.fit(X_train, y_train)
y_pred_ensemble = ensemble_model.predict(X_test)

# Inverse transforming the ensemble predictions
y_pred_ensemble = scaler_y.inverse_transform(y_pred_ensemble.reshape(-1, 1))

# Evaluating the ensemble model
mse_ensemble = mean_squared_error(y_test, y_pred_ensemble)
print("Mean Squared Error (Ensemble):", mse_ensemble)

# Plotting actual vs predicted values
plt.figure(figsize=(12, 8))
plt.plot(y_test, color='blue', label='Actual Power Output')
plt.plot(y_pred_lr, color='green', linestyle='--', label='LR Predicted Power Output')
plt.plot(y_pred_dt, color='orange', linestyle='--', label='DT Predicted Power Output')
plt.plot(y_pred_ensemble, color='red', linestyle='--', label='Ensemble Predicted Power Output')
plt.title('Ensemble Learning: Actual vs Predicted Power Output')
plt.xlabel('Samples')
plt.ylabel('Power Output (kW)')
plt.legend()
plt.show()
